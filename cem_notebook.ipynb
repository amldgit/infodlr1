{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0688169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.2\n",
      "torch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\" # does not matter chose tensorflow or torch or jax \n",
    "import keras\n",
    "print(keras.__version__)\n",
    "print(keras.backend.backend())\n",
    "from keras import layers\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit \n",
    "from sklearn.metrics import mean_squared_error # \n",
    "\n",
    "import keras_nlp # Requires keras-nlp to be installed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555a1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_BATCH_SIZE = 512 # as vram allows \n",
    "DEFAULT_VERBOSE_LEVEL = 2 # 0 for silent, 1 for progress bar, 2 for one line per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f6e8ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = loadmat(\"Xtrain.mat\")  \n",
    "x_raw = data[\"Xtrain\"].flatten()\n",
    "print(x_raw.shape)\n",
    "# Normalize\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(x_raw.reshape(-1, 1)).flatten()\n",
    "#X_scaled = scaler.inverse_transform(X_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# plot \n",
    "plt.plot(x_raw, label=\"raw\", c =\"blue\")\n",
    "plt.plot(X_scaled, label=\"scaled\", c =\"orange\")\n",
    "plt.title(\"Xtrain\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e30e355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f9b621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0c3adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35b320be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataset_2(data_sequence, lag):\n",
    "    \"\"\"Expects data_sequence to be a 2D numpy array where the time series is the first column.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(lag, len(data_sequence)):\n",
    "        X.append(data_sequence[i-lag:i, 0]) # Takes from the first column\n",
    "        y.append(data_sequence[i, 0])      # Takes from the first column\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "#  train_cv function - MODIFIED\n",
    "def train_cv_modified(model, full_dataset: pd.DataFrame, lag_order=7, epochs=200,\n",
    "                     patience_es=20, batch_size_param=DEFAULT_BATCH_SIZE, verbose_param=DEFAULT_VERBOSE_LEVEL):\n",
    "    #fit the scaler.\n",
    "    data_for_scaling = full_dataset.values\n",
    "    if data_for_scaling.ndim == 1: # Ensure it's 2D for scaler\n",
    "        data_for_scaling = data_for_scaling.reshape(-1, 1)\n",
    "\n",
    "    scaled_data_values = scaler.fit_transform(data_for_scaling)\n",
    "\n",
    "    model.scaled_data_full_history = scaled_data_values # Store the scaled version of the entire dataset\n",
    "\n",
    "    # Create sequences using the scaled data\n",
    "    X, y = create_dataset_2(scaled_data_values, lag_order)\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    fold_count = 0\n",
    "    fold_mses = []\n",
    "    all_fold_predictions = []\n",
    "    all_fold_actuals = []\n",
    "    \n",
    "    # Store histories if not using early stopping for averaging loss curves \n",
    "    training_losses_across_folds = []\n",
    "    validation_losses_across_folds = []\n",
    "\n",
    "    print(f\"\\nStarting Cross-Validation for model: {model.name}, Lag: {lag_order}\")\n",
    "\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        fold_count += 1\n",
    "        print(f\"  Fold {fold_count}:\")\n",
    "\n",
    "        X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "        y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "\n",
    "        # IMPORTANT: Reshape X_train_fold and X_test_fold for RNN/LSTM/GRU input\n",
    "        num_features = 1\n",
    "        X_train_fold_reshaped = X_train_fold.reshape((X_train_fold.shape[0], X_train_fold.shape[1], num_features))\n",
    "        X_test_fold_reshaped = X_test_fold.reshape((X_test_fold.shape[0], X_test_fold.shape[1], num_features))\n",
    "\n",
    "        \n",
    "        execution_history = model.fit(X_train_fold_reshaped, y_train_fold,\n",
    "                                      validation_data=(X_test_fold_reshaped, y_test_fold),\n",
    "                                      epochs=epochs,\n",
    "                                      batch_size=batch_size_param,                                      \n",
    "                                      verbose=verbose_param)\n",
    "        \n",
    "        training_losses_across_folds.append(execution_history.history['loss'])\n",
    "        validation_losses_across_folds.append(execution_history.history['val_loss'])\n",
    "\n",
    "\n",
    "        # Perform predictions\n",
    "        y_pred_scaled_fold = model.predict(X_test_fold_reshaped, verbose=verbose_param)\n",
    "\n",
    "        # Descale predictions and actual values\n",
    "        y_pred_descaled_fold = scaler.inverse_transform(y_pred_scaled_fold).flatten()\n",
    "        all_fold_predictions.append(y_pred_descaled_fold)\n",
    "\n",
    "        y_test_descaled_fold = scaler.inverse_transform(y_test_fold.reshape(-1, 1)).flatten()\n",
    "        all_fold_actuals.append(y_test_descaled_fold)\n",
    "\n",
    "        mse_fold = mean_squared_error(y_test_descaled_fold, y_pred_descaled_fold)\n",
    "        fold_mses.append(mse_fold)\n",
    "        print(f\"    Fold {fold_count} - Test MSE: {mse_fold:.4f}\")\n",
    "\n",
    "    avg_mse = np.mean(fold_mses)\n",
    "    std_mse = np.std(fold_mses)\n",
    "    print(f\"  Average MSE across all folds: {avg_mse:.4f} (+/- {std_mse:.4f})\")\n",
    "\n",
    "    # For history, if trying to average, ensure lists are not empty\n",
    "    avg_train_loss_curve = None\n",
    "    avg_val_loss_curve = None\n",
    "\n",
    "    if training_losses_across_folds and validation_losses_across_folds   :\n",
    "        # Pad shorter histories if epochs were fixed but something caused different lengths (should not happen if epochs fixed)\n",
    "        min_epochs_ran = min(len(h) for h in training_losses_across_folds)\n",
    "        trimmed_train_losses = [h[:min_epochs_ran] for h in training_losses_across_folds]\n",
    "        trimmed_val_losses = [h[:min_epochs_ran] for h in validation_losses_across_folds]\n",
    "        \n",
    "        if trimmed_train_losses:\n",
    "            avg_train_loss_curve = np.mean(np.array(trimmed_train_losses), axis=0)\n",
    "        if trimmed_val_losses:\n",
    "            avg_val_loss_curve = np.mean(np.array(trimmed_val_losses), axis=0)\n",
    "            \n",
    "  \n",
    "    results = {\n",
    "        \"avg_mse\": avg_mse,\n",
    "        \"std_mse\": std_mse,\n",
    "        \"fold_mses\": fold_mses,\n",
    "        \"all_fold_predictions\": all_fold_predictions, # List of arrays\n",
    "        \"all_fold_actuals\": all_fold_actuals,         # List of arrays\n",
    "        \"avg_train_loss_curve\": avg_train_loss_curve, # Average loss curve (if meaningful)\n",
    "        \"avg_val_loss_curve\": avg_val_loss_curve      # Average val_loss curve (if meaningful)\n",
    "    }\n",
    "    return results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b25ec074",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mat = loadmat(\"Xtrain.mat\")\n",
    "x_raw_numpy = data_mat[\"Xtrain\"].flatten() # This is a 1D NumPy array\n",
    "\n",
    "\n",
    "full_dataset_df = pd.DataFrame(x_raw_numpy, columns=['value'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0545910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model factories \n",
    "def build_rnn_model(input_len):\n",
    "    model = keras.Sequential([\n",
    "        layers.SimpleRNN(32, return_sequences=False, input_shape=(input_len, 1)),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def build_gru_model(input_len):\n",
    "    model = keras.Sequential([\n",
    "        layers.GRU(32, return_sequences=False, input_shape=(input_len, 1)),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def build_lstm_model(input_len):\n",
    "    model = keras.Sequential([\n",
    "        layers.LSTM(32, return_sequences=False, input_shape=(input_len, 1)),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_big_gru_model(input_len):\n",
    "    model = keras.Sequential([\n",
    "        layers.GRU(128, return_sequences=True, input_shape=(input_len, 1), name=\"gru1\"),\n",
    "        layers.GRU(64, return_sequences=True, name=\"gru2\"),\n",
    "        layers.Dropout(0.2, name=\"dropout1\"),\n",
    "        layers.GRU(32, return_sequences=False, name=\"gru3\"),\n",
    "        layers.Dense(1, name=\"output_dense\")\n",
    "    ], name=\"BigGRU\") \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_big_gru_model2(input_len):\n",
    "    model = keras.Sequential([\n",
    "        layers.GRU(256, return_sequences=True, input_shape=(input_len, 1), name=\"gru1\"),\n",
    "                layers.Dropout(0.2, name=\"dropout1\"),\n",
    "        layers.GRU(128, return_sequences=True, name=\"gru2\"),\n",
    "        layers.Dropout(0.2, name=\"dropout2\"),\n",
    "        layers.GRU(64, return_sequences=True, name=\"gru3\"),\n",
    "        layers.Dense(1, name=\"output_dense\")\n",
    "    ], name=\"BigGRU\") \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "def build_big_lstm_model(input_len):\n",
    "    model = keras.Sequential([\n",
    "        layers.LSTM(128, return_sequences=True, input_shape=(input_len, 1), name=\"lstm1\"),\n",
    "        # Removed redundant input_shape from second layer\n",
    "        layers.LSTM(64, return_sequences=True, name=\"lstm2\"),\n",
    "        layers.Dropout(0.2, name=\"dropout1\"),\n",
    "        layers.LSTM(32, return_sequences=False, name=\"lstm3\"),\n",
    "        layers.Dense(1, name=\"output_dense\")\n",
    "    ], name=\"BigLSTM\") \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b03cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- KerasNLP-based Transformer Model Builder ---\n",
    "def build_simple_transformer_model(    input_len,                  # Sequence length for the time series\n",
    "    model_dim=64,               # The hidden dimensionality of the Transformer\n",
    "    num_heads=4,                # Number of attention heads\n",
    "    ff_intermediate_dim=128,    # Dimensionality of the FFN's inner layer in each Transformer block\n",
    "    num_transformer_blocks=4,   # Number of Transformer blocks (fixed to 4 as requested)\n",
    "    mlp_units=[64],             # Units for the final MLP head\n",
    "    dropout_rate=0.1,           # Dropout rate used within Transformer blocks and MLP head\n",
    "    name_prefix=\"SimpleTransformer\"\n",
    "):\n",
    "    \n",
    "   \n",
    "    inputs = layers.Input(shape=(input_len, 1), name=\"input_timeseries\")\n",
    "\n",
    "    \n",
    "    x = layers.Dense(model_dim, name=\"input_projection\")(inputs)\n",
    "\n",
    "    x = keras_nlp.layers.PositionEmbedding(\n",
    "        sequence_length=input_len, name=\"positional_embedding\"\n",
    "    )(x)\n",
    "    x = layers.Dropout(dropout_rate, name=\"embedding_dropout\")(x)\n",
    "\n",
    "\n",
    "    for i in range(num_transformer_blocks):\n",
    "        x = keras_nlp.layers.TransformerEncoder(\n",
    "            intermediate_dim=ff_intermediate_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout_rate, # This dropout is applied in MHA and FFN within the block\n",
    "            name=f\"transformer_encoder_block_{i+1}\"\n",
    "        )(x) # KerasNLP handles the internal MHA, FFN, LayerNorm, and residuals\n",
    "\n",
    "    x = layers.Lambda(lambda seq: seq[:, -1, :], name=\"extract_last_timestep_output\")(x)\n",
    "\n",
    "    for units_val in mlp_units:\n",
    "        x = layers.Dense(units_val, activation=\"relu\")(x)\n",
    "        if dropout_rate > 0: # Using the same dropout_rate for MLP head here\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    outputs = layers.Dense(1, name=\"output_prediction\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=f\"{name_prefix}_{num_transformer_blocks}L\")\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aafb10c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training BigGRU with input_len: 50 ---\n",
      "\n",
      "Starting Cross-Validation for model: BigGRU, Lag: 50\n",
      "  Fold 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cemka\\anaconda3\\envs\\dl\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 - 3s - 334ms/step - loss: 0.0644 - val_loss: 0.0227\n",
      "Epoch 2/50\n",
      "10/10 - 3s - 327ms/step - loss: 0.0548 - val_loss: 0.0206\n",
      "Epoch 3/50\n",
      "10/10 - 3s - 315ms/step - loss: 0.0471 - val_loss: 0.0186\n",
      "Epoch 4/50\n",
      "10/10 - 3s - 311ms/step - loss: 0.0417 - val_loss: 0.0162\n",
      "Epoch 5/50\n",
      "10/10 - 3s - 311ms/step - loss: 0.0310 - val_loss: 0.0127\n",
      "Epoch 6/50\n",
      "10/10 - 3s - 338ms/step - loss: 0.0241 - val_loss: 0.0086\n",
      "Epoch 7/50\n",
      "10/10 - 3s - 306ms/step - loss: 0.0209 - val_loss: 0.0084\n",
      "Epoch 8/50\n",
      "10/10 - 3s - 304ms/step - loss: 0.0199 - val_loss: 0.0056\n",
      "Epoch 9/50\n",
      "10/10 - 3s - 307ms/step - loss: 0.0184 - val_loss: 0.0042\n",
      "Epoch 10/50\n",
      "10/10 - 3s - 310ms/step - loss: 0.0207 - val_loss: 0.0032\n",
      "Epoch 11/50\n",
      "10/10 - 3s - 310ms/step - loss: 0.0186 - val_loss: 0.0042\n",
      "Epoch 12/50\n",
      "10/10 - 3s - 312ms/step - loss: 0.0172 - val_loss: 0.0042\n",
      "Epoch 13/50\n",
      "10/10 - 3s - 301ms/step - loss: 0.0166 - val_loss: 0.0036\n",
      "Epoch 14/50\n",
      "10/10 - 3s - 310ms/step - loss: 0.0161 - val_loss: 0.0035\n",
      "Epoch 15/50\n",
      "10/10 - 3s - 305ms/step - loss: 0.0160 - val_loss: 0.0034\n",
      "Epoch 16/50\n",
      "10/10 - 3s - 311ms/step - loss: 0.0165 - val_loss: 0.0033\n",
      "Epoch 17/50\n",
      "10/10 - 3s - 299ms/step - loss: 0.0169 - val_loss: 0.0059\n",
      "Epoch 18/50\n",
      "10/10 - 3s - 304ms/step - loss: 0.0159 - val_loss: 0.0025\n",
      "Epoch 19/50\n",
      "10/10 - 3s - 307ms/step - loss: 0.0146 - val_loss: 0.0028\n",
      "Epoch 20/50\n",
      "10/10 - 3s - 304ms/step - loss: 0.0129 - val_loss: 0.0030\n",
      "Epoch 21/50\n",
      "10/10 - 3s - 299ms/step - loss: 0.0123 - val_loss: 0.0028\n",
      "Epoch 22/50\n",
      "10/10 - 3s - 298ms/step - loss: 0.0112 - val_loss: 0.0026\n",
      "Epoch 23/50\n",
      "10/10 - 3s - 302ms/step - loss: 0.0109 - val_loss: 0.0020\n",
      "Epoch 24/50\n",
      "10/10 - 3s - 295ms/step - loss: 0.0090 - val_loss: 0.0013\n",
      "Epoch 25/50\n",
      "10/10 - 3s - 292ms/step - loss: 0.0090 - val_loss: 0.0015\n",
      "Epoch 26/50\n",
      "10/10 - 3s - 305ms/step - loss: 0.0080 - val_loss: 6.0045e-04\n",
      "Epoch 27/50\n",
      "10/10 - 3s - 305ms/step - loss: 0.0077 - val_loss: 0.0023\n",
      "Epoch 28/50\n",
      "10/10 - 3s - 300ms/step - loss: 0.0094 - val_loss: 7.5737e-04\n",
      "Epoch 29/50\n",
      "10/10 - 3s - 312ms/step - loss: 0.0072 - val_loss: 0.0012\n",
      "Epoch 30/50\n",
      "10/10 - 3s - 297ms/step - loss: 0.0052 - val_loss: 7.5761e-04\n",
      "Epoch 31/50\n",
      "10/10 - 3s - 305ms/step - loss: 0.0052 - val_loss: 7.0355e-04\n",
      "Epoch 32/50\n",
      "10/10 - 3s - 299ms/step - loss: 0.0066 - val_loss: 7.7447e-04\n",
      "Epoch 33/50\n",
      "10/10 - 3s - 304ms/step - loss: 0.0059 - val_loss: 3.8882e-04\n",
      "Epoch 34/50\n",
      "10/10 - 3s - 303ms/step - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 35/50\n",
      "10/10 - 3s - 293ms/step - loss: 0.0056 - val_loss: 8.2045e-04\n",
      "Epoch 36/50\n",
      "10/10 - 3s - 300ms/step - loss: 0.0056 - val_loss: 4.6028e-04\n",
      "Epoch 37/50\n",
      "10/10 - 3s - 297ms/step - loss: 0.0049 - val_loss: 6.3180e-04\n",
      "Epoch 38/50\n",
      "10/10 - 3s - 288ms/step - loss: 0.0039 - val_loss: 5.4590e-04\n",
      "Epoch 39/50\n",
      "10/10 - 3s - 303ms/step - loss: 0.0053 - val_loss: 5.6540e-04\n",
      "Epoch 40/50\n",
      "10/10 - 3s - 299ms/step - loss: 0.0043 - val_loss: 5.6931e-04\n",
      "Epoch 41/50\n",
      "10/10 - 3s - 301ms/step - loss: 0.0044 - val_loss: 9.4269e-04\n",
      "Epoch 42/50\n",
      "10/10 - 3s - 291ms/step - loss: 0.0055 - val_loss: 0.0010\n",
      "Epoch 43/50\n",
      "10/10 - 3s - 293ms/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 44/50\n",
      "10/10 - 3s - 290ms/step - loss: 0.0040 - val_loss: 8.8728e-04\n",
      "Epoch 45/50\n",
      "10/10 - 3s - 292ms/step - loss: 0.0035 - val_loss: 8.8870e-04\n",
      "Epoch 46/50\n",
      "10/10 - 3s - 294ms/step - loss: 0.0036 - val_loss: 9.8635e-04\n",
      "Epoch 47/50\n",
      "10/10 - 3s - 296ms/step - loss: 0.0047 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "10/10 - 3s - 286ms/step - loss: 0.0048 - val_loss: 9.6000e-04\n",
      "Epoch 49/50\n",
      "10/10 - 3s - 298ms/step - loss: 0.0042 - val_loss: 8.7384e-04\n",
      "Epoch 50/50\n",
      "10/10 - 3s - 299ms/step - loss: 0.0039 - val_loss: 0.0016\n",
      "5/5 - 0s - 94ms/step\n",
      "    Fold 1 - Test MSE: 102.4009\n",
      "  Fold 2:\n",
      "Epoch 1/50\n",
      "20/20 - 5s - 256ms/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 2/50\n",
      "20/20 - 5s - 251ms/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 3/50\n",
      "20/20 - 5s - 252ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 4/50\n",
      "20/20 - 5s - 260ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 5/50\n",
      "20/20 - 5s - 243ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 6/50\n",
      "20/20 - 5s - 248ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 7/50\n",
      "20/20 - 5s - 253ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 8/50\n",
      "20/20 - 5s - 249ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 9/50\n",
      "20/20 - 5s - 264ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 10/50\n",
      "20/20 - 5s - 251ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 11/50\n",
      "20/20 - 5s - 252ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 12/50\n",
      "20/20 - 5s - 253ms/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 13/50\n",
      "20/20 - 5s - 260ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 14/50\n",
      "20/20 - 5s - 272ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 15/50\n",
      "20/20 - 5s - 250ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 16/50\n",
      "20/20 - 5s - 248ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 17/50\n",
      "20/20 - 5s - 245ms/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 18/50\n",
      "20/20 - 5s - 246ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 19/50\n",
      "20/20 - 5s - 246ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 20/50\n",
      "20/20 - 5s - 248ms/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 21/50\n",
      "20/20 - 5s - 246ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 22/50\n",
      "20/20 - 5s - 257ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 23/50\n",
      "20/20 - 5s - 241ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 24/50\n",
      "20/20 - 5s - 249ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 25/50\n",
      "20/20 - 5s - 246ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 26/50\n",
      "20/20 - 5s - 247ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 27/50\n",
      "20/20 - 5s - 241ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 28/50\n",
      "20/20 - 5s - 250ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 29/50\n",
      "20/20 - 5s - 248ms/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 30/50\n",
      "20/20 - 5s - 247ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 31/50\n",
      "20/20 - 5s - 250ms/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 32/50\n",
      "20/20 - 5s - 245ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 33/50\n",
      "20/20 - 5s - 244ms/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 34/50\n",
      "20/20 - 5s - 246ms/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 35/50\n",
      "20/20 - 5s - 247ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 36/50\n",
      "20/20 - 5s - 246ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 37/50\n",
      "20/20 - 5s - 252ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 38/50\n",
      "20/20 - 5s - 247ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 39/50\n",
      "20/20 - 5s - 245ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 40/50\n",
      "20/20 - 5s - 255ms/step - loss: 9.6019e-04 - val_loss: 0.0025\n",
      "Epoch 41/50\n",
      "20/20 - 5s - 242ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 42/50\n",
      "20/20 - 5s - 251ms/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 43/50\n",
      "20/20 - 5s - 249ms/step - loss: 7.8417e-04 - val_loss: 0.0022\n",
      "Epoch 44/50\n",
      "20/20 - 5s - 256ms/step - loss: 9.6345e-04 - val_loss: 0.0031\n",
      "Epoch 45/50\n",
      "20/20 - 5s - 268ms/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 46/50\n",
      "20/20 - 5s - 270ms/step - loss: 8.7257e-04 - val_loss: 0.0023\n",
      "Epoch 47/50\n",
      "20/20 - 6s - 287ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 48/50\n",
      "20/20 - 6s - 282ms/step - loss: 9.6672e-04 - val_loss: 0.0024\n",
      "Epoch 49/50\n",
      "20/20 - 5s - 260ms/step - loss: 8.9546e-04 - val_loss: 0.0024\n",
      "Epoch 50/50\n",
      "20/20 - 5s - 251ms/step - loss: 0.0010 - val_loss: 0.0021\n",
      "5/5 - 0s - 94ms/step\n",
      "    Fold 2 - Test MSE: 134.6242\n",
      "  Fold 3:\n",
      "Epoch 1/50\n",
      "30/30 - 8s - 256ms/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 2/50\n",
      "30/30 - 7s - 238ms/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 3/50\n",
      "30/30 - 8s - 265ms/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 4/50\n",
      "30/30 - 8s - 251ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 5/50\n",
      "30/30 - 7s - 239ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 6/50\n",
      "30/30 - 8s - 252ms/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 7/50\n",
      "30/30 - 8s - 253ms/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 8/50\n",
      "30/30 - 8s - 256ms/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 9/50\n",
      "30/30 - 8s - 261ms/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 10/50\n",
      "30/30 - 8s - 257ms/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 11/50\n",
      "30/30 - 8s - 253ms/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 12/50\n",
      "30/30 - 7s - 246ms/step - loss: 0.0010 - val_loss: 0.0023\n",
      "Epoch 13/50\n",
      "30/30 - 8s - 253ms/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 14/50\n",
      "30/30 - 7s - 249ms/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 15/50\n",
      "30/30 - 8s - 257ms/step - loss: 0.0010 - val_loss: 0.0025\n",
      "Epoch 16/50\n",
      "30/30 - 8s - 257ms/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 17/50\n",
      "30/30 - 7s - 247ms/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 18/50\n",
      "30/30 - 8s - 252ms/step - loss: 9.3512e-04 - val_loss: 0.0023\n",
      "Epoch 19/50\n",
      "30/30 - 7s - 247ms/step - loss: 9.7772e-04 - val_loss: 0.0023\n",
      "Epoch 20/50\n",
      "30/30 - 7s - 244ms/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 21/50\n",
      "30/30 - 7s - 249ms/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 22/50\n",
      "30/30 - 8s - 259ms/step - loss: 9.5281e-04 - val_loss: 0.0025\n",
      "Epoch 23/50\n",
      "30/30 - 8s - 257ms/step - loss: 9.0484e-04 - val_loss: 0.0019\n",
      "Epoch 24/50\n",
      "30/30 - 8s - 263ms/step - loss: 8.1291e-04 - val_loss: 0.0029\n",
      "Epoch 25/50\n",
      "30/30 - 8s - 265ms/step - loss: 9.9783e-04 - val_loss: 0.0022\n",
      "Epoch 26/50\n",
      "30/30 - 8s - 270ms/step - loss: 9.4404e-04 - val_loss: 0.0022\n",
      "Epoch 27/50\n",
      "30/30 - 8s - 260ms/step - loss: 9.8834e-04 - val_loss: 0.0023\n",
      "Epoch 28/50\n",
      "30/30 - 8s - 267ms/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 29/50\n",
      "30/30 - 8s - 255ms/step - loss: 8.6822e-04 - val_loss: 0.0024\n",
      "Epoch 30/50\n",
      "30/30 - 8s - 269ms/step - loss: 6.9711e-04 - val_loss: 0.0025\n",
      "Epoch 31/50\n",
      "30/30 - 8s - 270ms/step - loss: 7.4405e-04 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "30/30 - 8s - 250ms/step - loss: 8.7953e-04 - val_loss: 0.0030\n",
      "Epoch 33/50\n",
      "30/30 - 8s - 252ms/step - loss: 7.4291e-04 - val_loss: 0.0022\n",
      "Epoch 34/50\n",
      "30/30 - 8s - 265ms/step - loss: 8.5904e-04 - val_loss: 0.0030\n",
      "Epoch 35/50\n",
      "30/30 - 8s - 264ms/step - loss: 9.1165e-04 - val_loss: 0.0028\n",
      "Epoch 36/50\n",
      "30/30 - 8s - 251ms/step - loss: 9.0242e-04 - val_loss: 0.0027\n",
      "Epoch 37/50\n",
      "30/30 - 7s - 237ms/step - loss: 7.3068e-04 - val_loss: 0.0020\n",
      "Epoch 38/50\n",
      "30/30 - 7s - 236ms/step - loss: 8.4123e-04 - val_loss: 0.0037\n",
      "Epoch 39/50\n",
      "30/30 - 7s - 234ms/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 40/50\n",
      "30/30 - 7s - 239ms/step - loss: 9.0409e-04 - val_loss: 0.0025\n",
      "Epoch 41/50\n",
      "30/30 - 7s - 239ms/step - loss: 7.8253e-04 - val_loss: 0.0026\n",
      "Epoch 42/50\n",
      "30/30 - 7s - 234ms/step - loss: 6.2604e-04 - val_loss: 0.0030\n",
      "Epoch 43/50\n",
      "30/30 - 7s - 231ms/step - loss: 9.5906e-04 - val_loss: 0.0024\n",
      "Epoch 44/50\n",
      "30/30 - 7s - 231ms/step - loss: 8.2879e-04 - val_loss: 0.0022\n",
      "Epoch 45/50\n",
      "30/30 - 7s - 234ms/step - loss: 8.3650e-04 - val_loss: 0.0028\n",
      "Epoch 46/50\n",
      "30/30 - 7s - 235ms/step - loss: 9.7286e-04 - val_loss: 0.0034\n",
      "Epoch 47/50\n",
      "30/30 - 7s - 239ms/step - loss: 7.7827e-04 - val_loss: 0.0024\n",
      "Epoch 48/50\n",
      "30/30 - 7s - 238ms/step - loss: 9.3111e-04 - val_loss: 0.0025\n",
      "Epoch 49/50\n",
      "30/30 - 7s - 247ms/step - loss: 9.5988e-04 - val_loss: 0.0039\n",
      "Epoch 50/50\n",
      "30/30 - 7s - 237ms/step - loss: 8.5689e-04 - val_loss: 0.0027\n",
      "5/5 - 0s - 93ms/step\n",
      "    Fold 3 - Test MSE: 172.4662\n",
      "  Fold 4:\n",
      "Epoch 1/50\n",
      "40/40 - 9s - 231ms/step - loss: 9.7870e-04 - val_loss: 1.6451e-04\n",
      "Epoch 2/50\n",
      "40/40 - 9s - 230ms/step - loss: 0.0012 - val_loss: 1.3574e-04\n",
      "Epoch 3/50\n",
      "40/40 - 9s - 232ms/step - loss: 7.2690e-04 - val_loss: 3.5094e-04\n",
      "Epoch 4/50\n",
      "40/40 - 9s - 229ms/step - loss: 8.8545e-04 - val_loss: 2.0409e-04\n",
      "Epoch 5/50\n",
      "40/40 - 9s - 226ms/step - loss: 0.0011 - val_loss: 3.6921e-04\n",
      "Epoch 6/50\n",
      "40/40 - 9s - 224ms/step - loss: 0.0010 - val_loss: 3.3576e-05\n",
      "Epoch 7/50\n",
      "40/40 - 10s - 241ms/step - loss: 7.1195e-04 - val_loss: 1.0978e-04\n",
      "Epoch 8/50\n",
      "40/40 - 9s - 227ms/step - loss: 7.7436e-04 - val_loss: 9.5876e-05\n",
      "Epoch 9/50\n",
      "40/40 - 9s - 223ms/step - loss: 7.1524e-04 - val_loss: 6.6197e-05\n",
      "Epoch 10/50\n",
      "40/40 - 9s - 223ms/step - loss: 7.3283e-04 - val_loss: 4.8358e-05\n",
      "Epoch 11/50\n",
      "40/40 - 9s - 229ms/step - loss: 5.6861e-04 - val_loss: 6.4449e-05\n",
      "Epoch 12/50\n",
      "40/40 - 10s - 239ms/step - loss: 8.8205e-04 - val_loss: 1.7018e-04\n",
      "Epoch 13/50\n",
      "40/40 - 9s - 235ms/step - loss: 6.9155e-04 - val_loss: 1.7767e-04\n",
      "Epoch 14/50\n",
      "40/40 - 9s - 234ms/step - loss: 7.3227e-04 - val_loss: 2.8038e-05\n",
      "Epoch 15/50\n",
      "40/40 - 9s - 227ms/step - loss: 8.2560e-04 - val_loss: 9.4132e-05\n",
      "Epoch 16/50\n",
      "40/40 - 10s - 249ms/step - loss: 5.8439e-04 - val_loss: 8.6467e-05\n",
      "Epoch 17/50\n",
      "40/40 - 10s - 242ms/step - loss: 4.8901e-04 - val_loss: 8.0537e-05\n",
      "Epoch 18/50\n",
      "40/40 - 9s - 227ms/step - loss: 6.1047e-04 - val_loss: 8.0484e-05\n",
      "Epoch 19/50\n",
      "40/40 - 9s - 223ms/step - loss: 6.9627e-04 - val_loss: 5.7441e-05\n",
      "Epoch 20/50\n",
      "40/40 - 9s - 224ms/step - loss: 5.7141e-04 - val_loss: 1.5928e-04\n",
      "Epoch 21/50\n",
      "40/40 - 9s - 228ms/step - loss: 5.8135e-04 - val_loss: 6.0356e-05\n",
      "Epoch 22/50\n",
      "40/40 - 9s - 228ms/step - loss: 7.5619e-04 - val_loss: 1.1967e-04\n",
      "Epoch 23/50\n",
      "40/40 - 9s - 230ms/step - loss: 7.9075e-04 - val_loss: 9.3395e-05\n",
      "Epoch 24/50\n",
      "40/40 - 9s - 230ms/step - loss: 7.1813e-04 - val_loss: 1.3286e-04\n",
      "Epoch 25/50\n",
      "40/40 - 9s - 227ms/step - loss: 8.1233e-04 - val_loss: 2.6398e-04\n",
      "Epoch 26/50\n",
      "40/40 - 10s - 245ms/step - loss: 6.0108e-04 - val_loss: 5.7398e-05\n",
      "Epoch 27/50\n",
      "40/40 - 9s - 236ms/step - loss: 5.0564e-04 - val_loss: 1.8058e-04\n",
      "Epoch 28/50\n",
      "40/40 - 10s - 241ms/step - loss: 5.4880e-04 - val_loss: 9.2890e-05\n",
      "Epoch 29/50\n",
      "40/40 - 9s - 227ms/step - loss: 5.4934e-04 - val_loss: 6.2631e-05\n",
      "Epoch 30/50\n",
      "40/40 - 10s - 240ms/step - loss: 5.0402e-04 - val_loss: 6.4825e-05\n",
      "Epoch 31/50\n",
      "40/40 - 10s - 254ms/step - loss: 5.3971e-04 - val_loss: 7.7363e-05\n",
      "Epoch 32/50\n",
      "40/40 - 11s - 264ms/step - loss: 3.5824e-04 - val_loss: 7.1291e-05\n",
      "Epoch 33/50\n",
      "40/40 - 9s - 233ms/step - loss: 4.2622e-04 - val_loss: 8.8919e-05\n",
      "Epoch 34/50\n",
      "40/40 - 9s - 231ms/step - loss: 4.0421e-04 - val_loss: 1.2483e-04\n",
      "Epoch 35/50\n",
      "40/40 - 9s - 234ms/step - loss: 3.8607e-04 - val_loss: 5.9673e-05\n",
      "Epoch 36/50\n",
      "40/40 - 9s - 228ms/step - loss: 4.6161e-04 - val_loss: 1.5091e-04\n",
      "Epoch 37/50\n",
      "40/40 - 9s - 226ms/step - loss: 5.8097e-04 - val_loss: 8.7319e-05\n",
      "Epoch 38/50\n",
      "40/40 - 9s - 233ms/step - loss: 6.8117e-04 - val_loss: 1.8431e-04\n",
      "Epoch 39/50\n",
      "40/40 - 9s - 232ms/step - loss: 4.1455e-04 - val_loss: 1.4041e-04\n",
      "Epoch 40/50\n",
      "40/40 - 10s - 245ms/step - loss: 5.9471e-04 - val_loss: 9.3053e-05\n",
      "Epoch 41/50\n",
      "40/40 - 9s - 226ms/step - loss: 5.6651e-04 - val_loss: 2.4716e-05\n",
      "Epoch 42/50\n",
      "40/40 - 9s - 227ms/step - loss: 3.1477e-04 - val_loss: 5.8475e-05\n",
      "Epoch 43/50\n",
      "40/40 - 9s - 227ms/step - loss: 4.1932e-04 - val_loss: 3.5149e-05\n",
      "Epoch 44/50\n",
      "40/40 - 9s - 224ms/step - loss: 3.7447e-04 - val_loss: 1.1611e-04\n",
      "Epoch 45/50\n",
      "40/40 - 9s - 225ms/step - loss: 4.5619e-04 - val_loss: 9.7535e-05\n",
      "Epoch 46/50\n",
      "40/40 - 9s - 226ms/step - loss: 3.7694e-04 - val_loss: 1.3000e-04\n",
      "Epoch 47/50\n",
      "40/40 - 9s - 234ms/step - loss: 4.4625e-04 - val_loss: 5.1306e-05\n",
      "Epoch 48/50\n",
      "40/40 - 10s - 247ms/step - loss: 3.4238e-04 - val_loss: 4.0120e-05\n",
      "Epoch 49/50\n",
      "40/40 - 9s - 229ms/step - loss: 5.3297e-04 - val_loss: 4.2104e-04\n",
      "Epoch 50/50\n",
      "40/40 - 9s - 229ms/step - loss: 4.3121e-04 - val_loss: 2.0454e-04\n",
      "5/5 - 0s - 93ms/step\n",
      "    Fold 4 - Test MSE: 13.0922\n",
      "  Fold 5:\n",
      "Epoch 1/50\n",
      "50/50 - 11s - 226ms/step - loss: 4.7074e-04 - val_loss: 2.2398e-04\n",
      "Epoch 2/50\n",
      "50/50 - 11s - 225ms/step - loss: 3.3716e-04 - val_loss: 2.0473e-04\n",
      "Epoch 3/50\n",
      "50/50 - 11s - 224ms/step - loss: 4.2999e-04 - val_loss: 1.0092e-04\n",
      "Epoch 4/50\n",
      "50/50 - 11s - 226ms/step - loss: 3.4745e-04 - val_loss: 1.0826e-04\n",
      "Epoch 5/50\n",
      "50/50 - 12s - 245ms/step - loss: 3.0245e-04 - val_loss: 8.2960e-05\n",
      "Epoch 6/50\n",
      "50/50 - 11s - 228ms/step - loss: 2.9838e-04 - val_loss: 1.0396e-04\n",
      "Epoch 7/50\n",
      "50/50 - 11s - 227ms/step - loss: 3.2412e-04 - val_loss: 3.4896e-04\n",
      "Epoch 8/50\n",
      "50/50 - 11s - 226ms/step - loss: 4.6370e-04 - val_loss: 1.3044e-04\n",
      "Epoch 9/50\n",
      "50/50 - 12s - 236ms/step - loss: 3.4045e-04 - val_loss: 1.2453e-04\n",
      "Epoch 10/50\n",
      "50/50 - 12s - 247ms/step - loss: 4.6708e-04 - val_loss: 4.0301e-04\n",
      "Epoch 11/50\n",
      "50/50 - 11s - 222ms/step - loss: 6.4400e-04 - val_loss: 7.0924e-05\n",
      "Epoch 12/50\n",
      "50/50 - 11s - 222ms/step - loss: 3.3212e-04 - val_loss: 7.5856e-05\n",
      "Epoch 13/50\n",
      "50/50 - 11s - 226ms/step - loss: 4.5287e-04 - val_loss: 1.3715e-04\n",
      "Epoch 14/50\n",
      "50/50 - 12s - 235ms/step - loss: 3.4133e-04 - val_loss: 1.1069e-04\n",
      "Epoch 15/50\n",
      "50/50 - 11s - 220ms/step - loss: 3.1060e-04 - val_loss: 7.7943e-05\n",
      "Epoch 16/50\n",
      "50/50 - 11s - 227ms/step - loss: 2.6722e-04 - val_loss: 1.7203e-04\n",
      "Epoch 17/50\n",
      "50/50 - 11s - 224ms/step - loss: 2.7242e-04 - val_loss: 2.0680e-04\n",
      "Epoch 18/50\n",
      "50/50 - 11s - 221ms/step - loss: 2.8434e-04 - val_loss: 9.8343e-05\n",
      "Epoch 19/50\n",
      "50/50 - 11s - 222ms/step - loss: 3.3970e-04 - val_loss: 1.3443e-04\n",
      "Epoch 20/50\n",
      "50/50 - 11s - 219ms/step - loss: 3.2711e-04 - val_loss: 1.0577e-04\n",
      "Epoch 21/50\n",
      "50/50 - 11s - 220ms/step - loss: 3.1865e-04 - val_loss: 2.2187e-04\n",
      "Epoch 22/50\n",
      "50/50 - 11s - 228ms/step - loss: 3.4858e-04 - val_loss: 1.7158e-04\n",
      "Epoch 23/50\n",
      "50/50 - 12s - 242ms/step - loss: 3.3558e-04 - val_loss: 1.0475e-04\n",
      "Epoch 24/50\n",
      "50/50 - 12s - 231ms/step - loss: 3.6599e-04 - val_loss: 9.3666e-05\n",
      "Epoch 25/50\n",
      "50/50 - 12s - 233ms/step - loss: 3.0974e-04 - val_loss: 1.1009e-04\n",
      "Epoch 26/50\n",
      "50/50 - 12s - 236ms/step - loss: 4.2693e-04 - val_loss: 1.0902e-04\n",
      "Epoch 27/50\n",
      "50/50 - 11s - 228ms/step - loss: 3.4125e-04 - val_loss: 6.3072e-05\n",
      "Epoch 28/50\n",
      "50/50 - 11s - 221ms/step - loss: 2.3087e-04 - val_loss: 8.5013e-05\n",
      "Epoch 29/50\n",
      "50/50 - 11s - 217ms/step - loss: 2.9285e-04 - val_loss: 4.3512e-05\n",
      "Epoch 30/50\n",
      "50/50 - 12s - 238ms/step - loss: 2.3598e-04 - val_loss: 5.2144e-05\n",
      "Epoch 31/50\n",
      "50/50 - 11s - 229ms/step - loss: 4.4029e-04 - val_loss: 1.3714e-04\n",
      "Epoch 32/50\n",
      "50/50 - 11s - 229ms/step - loss: 2.4782e-04 - val_loss: 6.7901e-05\n",
      "Epoch 33/50\n",
      "50/50 - 12s - 238ms/step - loss: 3.2416e-04 - val_loss: 9.6254e-05\n",
      "Epoch 34/50\n",
      "50/50 - 10s - 209ms/step - loss: 3.3775e-04 - val_loss: 7.1101e-05\n",
      "Epoch 35/50\n",
      "50/50 - 10s - 205ms/step - loss: 5.9112e-04 - val_loss: 2.0206e-04\n",
      "Epoch 36/50\n",
      "50/50 - 10s - 204ms/step - loss: 3.3102e-04 - val_loss: 1.0553e-04\n",
      "Epoch 37/50\n",
      "50/50 - 10s - 203ms/step - loss: 3.1781e-04 - val_loss: 1.1361e-04\n",
      "Epoch 38/50\n",
      "50/50 - 10s - 204ms/step - loss: 2.7778e-04 - val_loss: 1.7587e-04\n",
      "Epoch 39/50\n",
      "50/50 - 10s - 203ms/step - loss: 2.8337e-04 - val_loss: 1.2401e-04\n",
      "Epoch 40/50\n",
      "50/50 - 10s - 203ms/step - loss: 3.9924e-04 - val_loss: 4.7402e-04\n",
      "Epoch 41/50\n",
      "50/50 - 10s - 204ms/step - loss: 2.6791e-04 - val_loss: 6.4281e-05\n",
      "Epoch 42/50\n",
      "50/50 - 10s - 203ms/step - loss: 2.4930e-04 - val_loss: 1.0873e-04\n",
      "Epoch 43/50\n",
      "50/50 - 10s - 203ms/step - loss: 2.2361e-04 - val_loss: 8.7645e-05\n",
      "Epoch 44/50\n",
      "50/50 - 10s - 203ms/step - loss: 3.5012e-04 - val_loss: 8.2989e-05\n",
      "Epoch 45/50\n",
      "50/50 - 10s - 204ms/step - loss: 2.9291e-04 - val_loss: 1.7311e-04\n",
      "Epoch 46/50\n",
      "50/50 - 10s - 203ms/step - loss: 3.0633e-04 - val_loss: 1.8548e-04\n",
      "Epoch 47/50\n",
      "50/50 - 10s - 204ms/step - loss: 2.6516e-04 - val_loss: 6.8465e-05\n",
      "Epoch 48/50\n",
      "50/50 - 10s - 206ms/step - loss: 3.0466e-04 - val_loss: 1.4886e-04\n",
      "Epoch 49/50\n",
      "50/50 - 10s - 207ms/step - loss: 2.5599e-04 - val_loss: 6.5784e-05\n",
      "Epoch 50/50\n",
      "50/50 - 10s - 204ms/step - loss: 2.9259e-04 - val_loss: 1.9061e-04\n",
      "5/5 - 0s - 77ms/step\n",
      "    Fold 5 - Test MSE: 12.2005\n",
      "  Average MSE across all folds: 86.9568 (+/- 64.6019)\n",
      "--- Finished BigGRU with input_len: 50, Avg MSE: 86.9568 ---\n",
      "--- Training BigGRU with input_len: 60 ---\n",
      "\n",
      "Starting Cross-Validation for model: BigGRU, Lag: 60\n",
      "  Fold 1:\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cemka\\anaconda3\\envs\\dl\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 3s - 316ms/step - loss: 0.0640 - val_loss: 0.0268\n",
      "Epoch 2/50\n",
      "10/10 - 3s - 319ms/step - loss: 0.0485 - val_loss: 0.0207\n",
      "Epoch 3/50\n",
      "10/10 - 3s - 315ms/step - loss: 0.0437 - val_loss: 0.0177\n",
      "Epoch 4/50\n",
      "10/10 - 3s - 317ms/step - loss: 0.0380 - val_loss: 0.0152\n",
      "Epoch 5/50\n",
      "10/10 - 3s - 315ms/step - loss: 0.0335 - val_loss: 0.0160\n",
      "Epoch 6/50\n",
      "10/10 - 3s - 315ms/step - loss: 0.0215 - val_loss: 0.0039\n",
      "Epoch 7/50\n",
      "10/10 - 3s - 313ms/step - loss: 0.0183 - val_loss: 0.0036\n",
      "Epoch 8/50\n",
      "10/10 - 3s - 322ms/step - loss: 0.0169 - val_loss: 0.0050\n",
      "Epoch 9/50\n",
      "10/10 - 3s - 317ms/step - loss: 0.0174 - val_loss: 0.0048\n",
      "Epoch 10/50\n",
      "10/10 - 3s - 315ms/step - loss: 0.0168 - val_loss: 0.0049\n",
      "Epoch 11/50\n",
      "10/10 - 3s - 315ms/step - loss: 0.0173 - val_loss: 0.0031\n",
      "Epoch 12/50\n",
      "10/10 - 3s - 333ms/step - loss: 0.0173 - val_loss: 0.0039\n",
      "Epoch 13/50\n",
      "10/10 - 3s - 315ms/step - loss: 0.0158 - val_loss: 0.0041\n",
      "Epoch 14/50\n",
      "10/10 - 3s - 314ms/step - loss: 0.0172 - val_loss: 0.0042\n",
      "Epoch 15/50\n",
      "10/10 - 3s - 315ms/step - loss: 0.0156 - val_loss: 0.0033\n",
      "Epoch 16/50\n",
      "10/10 - 3s - 316ms/step - loss: 0.0144 - val_loss: 0.0027\n",
      "Epoch 17/50\n",
      "10/10 - 3s - 310ms/step - loss: 0.0152 - val_loss: 0.0041\n",
      "Epoch 18/50\n",
      "10/10 - 3s - 332ms/step - loss: 0.0139 - val_loss: 0.0033\n",
      "Epoch 19/50\n",
      "10/10 - 3s - 311ms/step - loss: 0.0142 - val_loss: 0.0029\n",
      "Epoch 20/50\n",
      "10/10 - 3s - 308ms/step - loss: 0.0135 - val_loss: 0.0031\n",
      "Epoch 21/50\n",
      "10/10 - 3s - 309ms/step - loss: 0.0130 - val_loss: 0.0032\n",
      "Epoch 22/50\n",
      "10/10 - 3s - 308ms/step - loss: 0.0101 - val_loss: 0.0022\n",
      "Epoch 23/50\n",
      "10/10 - 3s - 309ms/step - loss: 0.0107 - val_loss: 0.0043\n",
      "Epoch 24/50\n",
      "10/10 - 3s - 307ms/step - loss: 0.0092 - val_loss: 0.0022\n",
      "Epoch 25/50\n",
      "10/10 - 3s - 308ms/step - loss: 0.0099 - val_loss: 0.0031\n",
      "Epoch 26/50\n",
      "10/10 - 3s - 310ms/step - loss: 0.0078 - val_loss: 0.0019\n",
      "Epoch 27/50\n",
      "10/10 - 3s - 311ms/step - loss: 0.0062 - val_loss: 0.0016\n",
      "Epoch 28/50\n",
      "10/10 - 3s - 312ms/step - loss: 0.0070 - val_loss: 0.0011\n",
      "Epoch 29/50\n",
      "10/10 - 3s - 311ms/step - loss: 0.0075 - val_loss: 3.3110e-04\n",
      "Epoch 30/50\n",
      "10/10 - 3s - 310ms/step - loss: 0.0066 - val_loss: 9.0561e-04\n",
      "Epoch 31/50\n",
      "10/10 - 3s - 308ms/step - loss: 0.0065 - val_loss: 8.3318e-04\n",
      "Epoch 32/50\n",
      "10/10 - 3s - 307ms/step - loss: 0.0048 - val_loss: 4.5452e-04\n",
      "Epoch 33/50\n",
      "10/10 - 3s - 308ms/step - loss: 0.0057 - val_loss: 9.0215e-04\n",
      "Epoch 34/50\n",
      "10/10 - 3s - 335ms/step - loss: 0.0046 - val_loss: 6.5034e-04\n",
      "Epoch 35/50\n",
      "10/10 - 3s - 324ms/step - loss: 0.0050 - val_loss: 6.3401e-04\n",
      "Epoch 36/50\n",
      "10/10 - 3s - 325ms/step - loss: 0.0047 - val_loss: 6.0563e-04\n",
      "Epoch 37/50\n",
      "10/10 - 3s - 323ms/step - loss: 0.0045 - val_loss: 0.0016\n",
      "Epoch 38/50\n",
      "10/10 - 3s - 317ms/step - loss: 0.0046 - val_loss: 9.8887e-04\n",
      "Epoch 39/50\n",
      "10/10 - 3s - 318ms/step - loss: 0.0038 - val_loss: 1.9086e-04\n",
      "Epoch 40/50\n",
      "10/10 - 3s - 315ms/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 41/50\n",
      "10/10 - 3s - 318ms/step - loss: 0.0052 - val_loss: 1.7163e-04\n",
      "Epoch 42/50\n",
      "10/10 - 3s - 314ms/step - loss: 0.0059 - val_loss: 7.0052e-04\n",
      "Epoch 43/50\n",
      "10/10 - 3s - 319ms/step - loss: 0.0054 - val_loss: 0.0019\n",
      "Epoch 44/50\n",
      "10/10 - 3s - 318ms/step - loss: 0.0049 - val_loss: 5.5038e-04\n",
      "Epoch 45/50\n",
      "10/10 - 3s - 321ms/step - loss: 0.0038 - val_loss: 5.0656e-04\n",
      "Epoch 46/50\n",
      "10/10 - 3s - 320ms/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 47/50\n",
      "10/10 - 3s - 314ms/step - loss: 0.0038 - val_loss: 3.6317e-04\n",
      "Epoch 48/50\n",
      "10/10 - 3s - 316ms/step - loss: 0.0034 - val_loss: 4.6620e-04\n",
      "Epoch 49/50\n",
      "10/10 - 3s - 314ms/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 50/50\n",
      "10/10 - 3s - 320ms/step - loss: 0.0045 - val_loss: 4.1867e-04\n",
      "5/5 - 0s - 98ms/step\n",
      "    Fold 1 - Test MSE: 26.7987\n",
      "  Fold 2:\n",
      "Epoch 1/50\n",
      "20/20 - 6s - 278ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 2/50\n",
      "20/20 - 6s - 280ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 3/50\n",
      "20/20 - 6s - 279ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 4/50\n",
      "20/20 - 5s - 275ms/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 5/50\n",
      "20/20 - 6s - 278ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 6/50\n",
      "20/20 - 6s - 279ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 7/50\n",
      "20/20 - 6s - 280ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 8/50\n",
      "20/20 - 6s - 278ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 9/50\n",
      "20/20 - 6s - 275ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 10/50\n",
      "20/20 - 6s - 276ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 11/50\n",
      "20/20 - 6s - 285ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 12/50\n",
      "20/20 - 6s - 276ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 13/50\n",
      "20/20 - 6s - 277ms/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 14/50\n",
      "20/20 - 6s - 281ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 15/50\n",
      "20/20 - 6s - 279ms/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 16/50\n",
      "20/20 - 6s - 278ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 17/50\n",
      "20/20 - 6s - 285ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 18/50\n",
      "20/20 - 6s - 305ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 19/50\n",
      "20/20 - 7s - 334ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 20/50\n",
      "20/20 - 6s - 292ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 21/50\n",
      "20/20 - 7s - 331ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 22/50\n",
      "20/20 - 6s - 309ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 23/50\n",
      "20/20 - 6s - 324ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 24/50\n",
      "20/20 - 6s - 311ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 25/50\n",
      "20/20 - 6s - 315ms/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 26/50\n",
      "20/20 - 6s - 315ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 27/50\n",
      "20/20 - 6s - 313ms/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 28/50\n",
      "20/20 - 6s - 293ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 29/50\n",
      "20/20 - 6s - 296ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 30/50\n",
      "20/20 - 6s - 301ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 31/50\n",
      "20/20 - 6s - 303ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 32/50\n",
      "20/20 - 6s - 294ms/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 33/50\n",
      "20/20 - 6s - 295ms/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 34/50\n",
      "20/20 - 6s - 296ms/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 35/50\n",
      "20/20 - 6s - 291ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 36/50\n",
      "20/20 - 6s - 294ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 37/50\n",
      "20/20 - 6s - 303ms/step - loss: 8.8485e-04 - val_loss: 0.0020\n",
      "Epoch 38/50\n",
      "20/20 - 6s - 299ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 39/50\n",
      "20/20 - 6s - 302ms/step - loss: 8.4629e-04 - val_loss: 0.0018\n",
      "Epoch 40/50\n",
      "20/20 - 6s - 295ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 41/50\n",
      "20/20 - 6s - 304ms/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 42/50\n",
      "20/20 - 6s - 303ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 43/50\n",
      "20/20 - 6s - 304ms/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 44/50\n",
      "20/20 - 6s - 299ms/step - loss: 9.6508e-04 - val_loss: 0.0017\n",
      "Epoch 45/50\n",
      "20/20 - 6s - 298ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 46/50\n",
      "20/20 - 6s - 299ms/step - loss: 9.1332e-04 - val_loss: 0.0022\n",
      "Epoch 47/50\n",
      "20/20 - 6s - 299ms/step - loss: 9.5542e-04 - val_loss: 0.0023\n",
      "Epoch 48/50\n",
      "20/20 - 6s - 296ms/step - loss: 8.9796e-04 - val_loss: 0.0016\n",
      "Epoch 49/50\n",
      "20/20 - 6s - 293ms/step - loss: 9.4503e-04 - val_loss: 0.0018\n",
      "Epoch 50/50\n",
      "20/20 - 6s - 297ms/step - loss: 0.0011 - val_loss: 0.0022\n",
      "5/5 - 1s - 107ms/step\n",
      "    Fold 2 - Test MSE: 137.9769\n",
      "  Fold 3:\n",
      "Epoch 1/50\n",
      "30/30 - 8s - 282ms/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 2/50\n",
      "30/30 - 9s - 284ms/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 3/50\n",
      "30/30 - 8s - 278ms/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      "30/30 - 8s - 280ms/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 5/50\n",
      "30/30 - 8s - 273ms/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 6/50\n",
      "30/30 - 9s - 286ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 7/50\n",
      "30/30 - 8s - 276ms/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 8/50\n",
      "30/30 - 8s - 279ms/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 9/50\n",
      "30/30 - 8s - 282ms/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 10/50\n",
      "30/30 - 9s - 283ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 11/50\n",
      "30/30 - 9s - 285ms/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 12/50\n",
      "30/30 - 8s - 278ms/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 13/50\n",
      "30/30 - 8s - 280ms/step - loss: 9.0781e-04 - val_loss: 0.0021\n",
      "Epoch 14/50\n",
      "30/30 - 8s - 277ms/step - loss: 9.3201e-04 - val_loss: 0.0021\n",
      "Epoch 15/50\n",
      "30/30 - 9s - 298ms/step - loss: 9.1559e-04 - val_loss: 0.0021\n",
      "Epoch 16/50\n",
      "30/30 - 9s - 295ms/step - loss: 8.2605e-04 - val_loss: 0.0018\n",
      "Epoch 17/50\n",
      "30/30 - 9s - 294ms/step - loss: 9.1021e-04 - val_loss: 0.0018\n",
      "Epoch 18/50\n",
      "30/30 - 9s - 298ms/step - loss: 8.8419e-04 - val_loss: 0.0021\n",
      "Epoch 19/50\n",
      "30/30 - 8s - 275ms/step - loss: 7.6126e-04 - val_loss: 0.0021\n",
      "Epoch 20/50\n",
      "30/30 - 8s - 257ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 21/50\n",
      "30/30 - 8s - 281ms/step - loss: 8.6450e-04 - val_loss: 0.0017\n",
      "Epoch 22/50\n",
      "30/30 - 10s - 318ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 23/50\n",
      "30/30 - 9s - 307ms/step - loss: 6.6899e-04 - val_loss: 0.0016\n",
      "Epoch 24/50\n",
      "30/30 - 8s - 281ms/step - loss: 9.4002e-04 - val_loss: 0.0019\n",
      "Epoch 25/50\n",
      "30/30 - 8s - 276ms/step - loss: 8.7455e-04 - val_loss: 0.0016\n",
      "Epoch 26/50\n",
      "30/30 - 8s - 270ms/step - loss: 9.2587e-04 - val_loss: 0.0017\n",
      "Epoch 27/50\n",
      "30/30 - 8s - 257ms/step - loss: 8.9710e-04 - val_loss: 0.0016\n",
      "Epoch 28/50\n",
      "30/30 - 8s - 255ms/step - loss: 8.5155e-04 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "30/30 - 8s - 262ms/step - loss: 5.6478e-04 - val_loss: 0.0018\n",
      "Epoch 30/50\n",
      "30/30 - 8s - 263ms/step - loss: 7.1430e-04 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "30/30 - 8s - 263ms/step - loss: 6.7456e-04 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "30/30 - 8s - 264ms/step - loss: 6.7331e-04 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "30/30 - 8s - 263ms/step - loss: 8.8283e-04 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "30/30 - 8s - 266ms/step - loss: 5.5212e-04 - val_loss: 0.0012\n",
      "Epoch 35/50\n",
      "30/30 - 8s - 265ms/step - loss: 6.4891e-04 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "30/30 - 9s - 293ms/step - loss: 8.2271e-04 - val_loss: 0.0014\n",
      "Epoch 37/50\n",
      "30/30 - 8s - 281ms/step - loss: 8.2296e-04 - val_loss: 0.0014\n",
      "Epoch 38/50\n",
      "30/30 - 9s - 286ms/step - loss: 4.8781e-04 - val_loss: 8.4886e-04\n",
      "Epoch 39/50\n",
      "30/30 - 8s - 281ms/step - loss: 8.3323e-04 - val_loss: 0.0014\n",
      "Epoch 40/50\n",
      "30/30 - 8s - 282ms/step - loss: 9.1125e-04 - val_loss: 0.0012\n",
      "Epoch 41/50\n",
      "30/30 - 9s - 284ms/step - loss: 8.0353e-04 - val_loss: 0.0018\n",
      "Epoch 42/50\n",
      "30/30 - 8s - 280ms/step - loss: 8.7167e-04 - val_loss: 0.0021\n",
      "Epoch 43/50\n",
      "30/30 - 9s - 291ms/step - loss: 6.3392e-04 - val_loss: 0.0013\n",
      "Epoch 44/50\n",
      "30/30 - 8s - 282ms/step - loss: 5.2050e-04 - val_loss: 0.0010\n",
      "Epoch 45/50\n",
      "30/30 - 8s - 278ms/step - loss: 8.7816e-04 - val_loss: 0.0010\n",
      "Epoch 46/50\n",
      "30/30 - 9s - 285ms/step - loss: 7.3483e-04 - val_loss: 0.0022\n",
      "Epoch 47/50\n",
      "30/30 - 9s - 287ms/step - loss: 6.9389e-04 - val_loss: 0.0018\n",
      "Epoch 48/50\n",
      "30/30 - 9s - 284ms/step - loss: 8.5461e-04 - val_loss: 0.0014\n",
      "Epoch 49/50\n",
      "30/30 - 8s - 283ms/step - loss: 7.4360e-04 - val_loss: 8.7344e-04\n",
      "Epoch 50/50\n",
      "30/30 - 8s - 281ms/step - loss: 8.2197e-04 - val_loss: 0.0016\n",
      "5/5 - 1s - 109ms/step\n",
      "    Fold 3 - Test MSE: 101.2004\n",
      "  Fold 4:\n",
      "Epoch 1/50\n",
      "40/40 - 11s - 276ms/step - loss: 8.8048e-04 - val_loss: 5.5555e-05\n",
      "Epoch 2/50\n",
      "40/40 - 11s - 277ms/step - loss: 6.1213e-04 - val_loss: 5.7068e-05\n",
      "Epoch 3/50\n",
      "40/40 - 11s - 272ms/step - loss: 0.0012 - val_loss: 2.1395e-04\n",
      "Epoch 4/50\n",
      "40/40 - 11s - 273ms/step - loss: 9.6785e-04 - val_loss: 1.9698e-04\n",
      "Epoch 5/50\n",
      "40/40 - 11s - 277ms/step - loss: 6.8733e-04 - val_loss: 5.9109e-05\n",
      "Epoch 6/50\n",
      "40/40 - 11s - 276ms/step - loss: 8.9543e-04 - val_loss: 1.7930e-04\n",
      "Epoch 7/50\n",
      "40/40 - 11s - 274ms/step - loss: 6.7493e-04 - val_loss: 1.6232e-04\n",
      "Epoch 8/50\n",
      "40/40 - 11s - 276ms/step - loss: 8.0225e-04 - val_loss: 2.2537e-04\n",
      "Epoch 9/50\n",
      "40/40 - 12s - 291ms/step - loss: 6.4699e-04 - val_loss: 9.3935e-05\n",
      "Epoch 10/50\n",
      "40/40 - 12s - 302ms/step - loss: 5.9129e-04 - val_loss: 1.0131e-04\n",
      "Epoch 11/50\n",
      "40/40 - 11s - 287ms/step - loss: 5.0564e-04 - val_loss: 1.0872e-04\n",
      "Epoch 12/50\n",
      "40/40 - 10s - 252ms/step - loss: 6.5842e-04 - val_loss: 9.4237e-05\n",
      "Epoch 13/50\n",
      "40/40 - 10s - 257ms/step - loss: 7.8465e-04 - val_loss: 3.6951e-04\n",
      "Epoch 14/50\n",
      "40/40 - 10s - 248ms/step - loss: 9.9109e-04 - val_loss: 5.4599e-05\n",
      "Epoch 15/50\n",
      "40/40 - 11s - 266ms/step - loss: 5.0196e-04 - val_loss: 5.3317e-05\n",
      "Epoch 16/50\n",
      "40/40 - 10s - 249ms/step - loss: 5.8036e-04 - val_loss: 1.4916e-04\n",
      "Epoch 17/50\n",
      "40/40 - 10s - 250ms/step - loss: 5.6747e-04 - val_loss: 5.2573e-05\n",
      "Epoch 18/50\n",
      "40/40 - 10s - 250ms/step - loss: 5.8865e-04 - val_loss: 6.1326e-05\n",
      "Epoch 19/50\n",
      "40/40 - 10s - 249ms/step - loss: 5.2976e-04 - val_loss: 2.3043e-05\n",
      "Epoch 20/50\n",
      "40/40 - 10s - 249ms/step - loss: 5.1856e-04 - val_loss: 3.0389e-05\n",
      "Epoch 21/50\n",
      "40/40 - 10s - 260ms/step - loss: 5.6135e-04 - val_loss: 2.0529e-04\n",
      "Epoch 22/50\n",
      "40/40 - 10s - 259ms/step - loss: 5.5767e-04 - val_loss: 1.2325e-04\n",
      "Epoch 23/50\n",
      "40/40 - 10s - 257ms/step - loss: 4.3584e-04 - val_loss: 5.5396e-05\n",
      "Epoch 24/50\n",
      "40/40 - 11s - 271ms/step - loss: 3.9727e-04 - val_loss: 1.5026e-04\n",
      "Epoch 25/50\n",
      "40/40 - 11s - 273ms/step - loss: 4.3604e-04 - val_loss: 1.6056e-04\n",
      "Epoch 26/50\n",
      "40/40 - 11s - 274ms/step - loss: 6.7166e-04 - val_loss: 8.6658e-05\n",
      "Epoch 27/50\n",
      "40/40 - 11s - 284ms/step - loss: 4.0682e-04 - val_loss: 1.1194e-04\n",
      "Epoch 28/50\n",
      "40/40 - 11s - 274ms/step - loss: 4.9333e-04 - val_loss: 7.1579e-05\n",
      "Epoch 29/50\n",
      "40/40 - 11s - 271ms/step - loss: 5.3835e-04 - val_loss: 3.4302e-05\n",
      "Epoch 30/50\n",
      "40/40 - 11s - 275ms/step - loss: 7.1274e-04 - val_loss: 4.0934e-05\n",
      "Epoch 31/50\n",
      "40/40 - 11s - 283ms/step - loss: 5.1287e-04 - val_loss: 1.2176e-04\n",
      "Epoch 32/50\n",
      "40/40 - 11s - 274ms/step - loss: 5.3314e-04 - val_loss: 2.4984e-04\n",
      "Epoch 33/50\n",
      "40/40 - 11s - 279ms/step - loss: 3.9601e-04 - val_loss: 3.5290e-04\n",
      "Epoch 34/50\n",
      "40/40 - 11s - 273ms/step - loss: 3.8004e-04 - val_loss: 1.2786e-04\n",
      "Epoch 35/50\n",
      "40/40 - 11s - 278ms/step - loss: 3.7734e-04 - val_loss: 1.9959e-04\n",
      "Epoch 36/50\n",
      "40/40 - 11s - 287ms/step - loss: 3.3677e-04 - val_loss: 6.1596e-05\n",
      "Epoch 37/50\n",
      "40/40 - 11s - 281ms/step - loss: 3.5634e-04 - val_loss: 3.2936e-05\n",
      "Epoch 38/50\n",
      "40/40 - 11s - 271ms/step - loss: 4.2229e-04 - val_loss: 2.3385e-04\n",
      "Epoch 39/50\n",
      "40/40 - 11s - 276ms/step - loss: 4.1818e-04 - val_loss: 1.0634e-04\n",
      "Epoch 40/50\n",
      "40/40 - 11s - 276ms/step - loss: 3.2539e-04 - val_loss: 1.2376e-04\n",
      "Epoch 41/50\n",
      "40/40 - 11s - 280ms/step - loss: 3.0227e-04 - val_loss: 6.9182e-05\n",
      "Epoch 42/50\n",
      "40/40 - 12s - 295ms/step - loss: 5.7820e-04 - val_loss: 2.8004e-04\n",
      "Epoch 43/50\n",
      "40/40 - 12s - 289ms/step - loss: 3.9129e-04 - val_loss: 5.0451e-05\n",
      "Epoch 44/50\n",
      "40/40 - 11s - 277ms/step - loss: 3.9657e-04 - val_loss: 9.8900e-05\n",
      "Epoch 45/50\n",
      "40/40 - 12s - 289ms/step - loss: 3.7744e-04 - val_loss: 6.3127e-05\n",
      "Epoch 46/50\n",
      "40/40 - 11s - 285ms/step - loss: 4.1211e-04 - val_loss: 3.1679e-04\n",
      "Epoch 47/50\n",
      "40/40 - 11s - 284ms/step - loss: 3.4531e-04 - val_loss: 4.6373e-05\n",
      "Epoch 48/50\n",
      "40/40 - 11s - 277ms/step - loss: 3.1258e-04 - val_loss: 1.3933e-04\n",
      "Epoch 49/50\n",
      "40/40 - 11s - 273ms/step - loss: 3.9398e-04 - val_loss: 4.9512e-05\n",
      "Epoch 50/50\n",
      "40/40 - 11s - 277ms/step - loss: 3.7904e-04 - val_loss: 8.8851e-05\n",
      "5/5 - 1s - 118ms/step\n",
      "    Fold 4 - Test MSE: 5.6873\n",
      "  Fold 5:\n",
      "Epoch 1/50\n",
      "49/49 - 14s - 282ms/step - loss: 5.7691e-04 - val_loss: 1.9947e-04\n",
      "Epoch 2/50\n",
      "49/49 - 12s - 254ms/step - loss: 3.6611e-04 - val_loss: 8.2537e-05\n",
      "Epoch 3/50\n",
      "49/49 - 12s - 248ms/step - loss: 3.2877e-04 - val_loss: 1.1868e-04\n",
      "Epoch 4/50\n",
      "49/49 - 12s - 249ms/step - loss: 2.7673e-04 - val_loss: 1.4068e-04\n",
      "Epoch 5/50\n",
      "49/49 - 12s - 243ms/step - loss: 3.3074e-04 - val_loss: 6.6628e-05\n",
      "Epoch 6/50\n",
      "49/49 - 12s - 246ms/step - loss: 3.0083e-04 - val_loss: 8.7396e-05\n",
      "Epoch 7/50\n",
      "49/49 - 12s - 247ms/step - loss: 3.5963e-04 - val_loss: 4.6919e-05\n",
      "Epoch 8/50\n",
      "49/49 - 12s - 247ms/step - loss: 2.7011e-04 - val_loss: 1.0433e-04\n",
      "Epoch 9/50\n",
      "49/49 - 12s - 248ms/step - loss: 2.9894e-04 - val_loss: 6.4989e-05\n",
      "Epoch 10/50\n",
      "49/49 - 12s - 252ms/step - loss: 3.9693e-04 - val_loss: 1.4106e-04\n",
      "Epoch 11/50\n",
      "49/49 - 12s - 250ms/step - loss: 3.6302e-04 - val_loss: 1.1218e-04\n",
      "Epoch 12/50\n",
      "49/49 - 12s - 246ms/step - loss: 3.4705e-04 - val_loss: 3.2066e-04\n",
      "Epoch 13/50\n",
      "49/49 - 12s - 246ms/step - loss: 3.2623e-04 - val_loss: 1.5501e-04\n",
      "Epoch 14/50\n",
      "49/49 - 12s - 244ms/step - loss: 3.1462e-04 - val_loss: 1.7925e-04\n",
      "Epoch 15/50\n",
      "49/49 - 12s - 248ms/step - loss: 3.3305e-04 - val_loss: 3.0904e-05\n",
      "Epoch 16/50\n",
      "49/49 - 12s - 244ms/step - loss: 3.6594e-04 - val_loss: 1.6896e-04\n",
      "Epoch 17/50\n",
      "49/49 - 12s - 245ms/step - loss: 3.4954e-04 - val_loss: 9.8218e-05\n",
      "Epoch 18/50\n",
      "49/49 - 12s - 244ms/step - loss: 3.5763e-04 - val_loss: 9.4018e-05\n",
      "Epoch 19/50\n",
      "49/49 - 12s - 239ms/step - loss: 3.2174e-04 - val_loss: 8.6694e-05\n",
      "Epoch 20/50\n",
      "49/49 - 12s - 247ms/step - loss: 2.7017e-04 - val_loss: 5.2618e-05\n",
      "Epoch 21/50\n",
      "49/49 - 12s - 248ms/step - loss: 3.1264e-04 - val_loss: 1.9017e-04\n",
      "Epoch 22/50\n",
      "49/49 - 12s - 247ms/step - loss: 2.6339e-04 - val_loss: 8.6543e-05\n",
      "Epoch 23/50\n",
      "49/49 - 12s - 253ms/step - loss: 3.9288e-04 - val_loss: 1.1484e-04\n",
      "Epoch 24/50\n",
      "49/49 - 12s - 247ms/step - loss: 3.0267e-04 - val_loss: 1.7238e-04\n",
      "Epoch 25/50\n",
      "49/49 - 12s - 243ms/step - loss: 5.0112e-04 - val_loss: 4.3572e-04\n",
      "Epoch 26/50\n",
      "49/49 - 12s - 242ms/step - loss: 3.3157e-04 - val_loss: 7.8053e-05\n",
      "Epoch 27/50\n",
      "49/49 - 12s - 241ms/step - loss: 2.4265e-04 - val_loss: 4.2607e-05\n",
      "Epoch 28/50\n",
      "49/49 - 12s - 251ms/step - loss: 3.0250e-04 - val_loss: 9.4625e-05\n",
      "Epoch 29/50\n",
      "49/49 - 13s - 256ms/step - loss: 2.8704e-04 - val_loss: 1.6360e-04\n",
      "Epoch 30/50\n",
      "49/49 - 13s - 257ms/step - loss: 4.0835e-04 - val_loss: 1.6264e-04\n",
      "Epoch 31/50\n",
      "49/49 - 12s - 243ms/step - loss: 4.0719e-04 - val_loss: 2.1166e-04\n",
      "Epoch 32/50\n",
      "49/49 - 12s - 243ms/step - loss: 2.7406e-04 - val_loss: 4.0432e-05\n",
      "Epoch 33/50\n",
      "49/49 - 12s - 240ms/step - loss: 4.4401e-04 - val_loss: 8.9050e-05\n",
      "Epoch 34/50\n",
      "49/49 - 12s - 240ms/step - loss: 3.5514e-04 - val_loss: 1.5910e-04\n",
      "Epoch 35/50\n",
      "49/49 - 12s - 240ms/step - loss: 2.3064e-04 - val_loss: 2.6821e-04\n",
      "Epoch 36/50\n",
      "49/49 - 12s - 242ms/step - loss: 3.0605e-04 - val_loss: 4.1566e-05\n",
      "Epoch 37/50\n",
      "49/49 - 12s - 251ms/step - loss: 3.0494e-04 - val_loss: 2.7574e-04\n",
      "Epoch 38/50\n",
      "49/49 - 12s - 251ms/step - loss: 3.0036e-04 - val_loss: 4.7620e-05\n",
      "Epoch 39/50\n",
      "49/49 - 12s - 243ms/step - loss: 3.7939e-04 - val_loss: 6.5740e-05\n",
      "Epoch 40/50\n",
      "49/49 - 12s - 249ms/step - loss: 2.8580e-04 - val_loss: 6.5435e-05\n",
      "Epoch 41/50\n",
      "49/49 - 12s - 251ms/step - loss: 3.4553e-04 - val_loss: 1.2292e-04\n",
      "Epoch 42/50\n",
      "49/49 - 12s - 241ms/step - loss: 2.9009e-04 - val_loss: 6.2139e-05\n",
      "Epoch 43/50\n",
      "49/49 - 12s - 241ms/step - loss: 3.4240e-04 - val_loss: 1.0960e-04\n",
      "Epoch 44/50\n",
      "49/49 - 12s - 241ms/step - loss: 3.3022e-04 - val_loss: 6.0821e-05\n",
      "Epoch 45/50\n",
      "49/49 - 12s - 250ms/step - loss: 3.0119e-04 - val_loss: 1.1004e-04\n",
      "Epoch 46/50\n",
      "49/49 - 12s - 254ms/step - loss: 3.2108e-04 - val_loss: 1.7254e-04\n",
      "Epoch 47/50\n",
      "49/49 - 12s - 249ms/step - loss: 3.0359e-04 - val_loss: 6.8117e-05\n",
      "Epoch 48/50\n",
      "49/49 - 13s - 258ms/step - loss: 2.6084e-04 - val_loss: 5.3380e-05\n",
      "Epoch 49/50\n",
      "49/49 - 12s - 246ms/step - loss: 2.4723e-04 - val_loss: 1.8255e-04\n",
      "Epoch 50/50\n",
      "49/49 - 12s - 245ms/step - loss: 4.6770e-04 - val_loss: 5.5965e-05\n",
      "5/5 - 0s - 91ms/step\n",
      "    Fold 5 - Test MSE: 3.5823\n",
      "  Average MSE across all folds: 55.0491 (+/- 54.5719)\n",
      "--- Finished BigGRU with input_len: 60, Avg MSE: 55.0491 ---\n",
      "--- Training BigGRU2 with input_len: 50 ---\n",
      "\n",
      "Starting Cross-Validation for model: BigGRU, Lag: 50\n",
      "  Fold 1:\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cemka\\anaconda3\\envs\\dl\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 3s - 295ms/step - loss: 0.0583 - val_loss: 0.0219\n",
      "Epoch 2/50\n",
      "10/10 - 3s - 283ms/step - loss: 0.0521 - val_loss: 0.0221\n",
      "Epoch 3/50\n",
      "10/10 - 3s - 284ms/step - loss: 0.0502 - val_loss: 0.0214\n",
      "Epoch 4/50\n",
      "10/10 - 3s - 274ms/step - loss: 0.0500 - val_loss: 0.0212\n",
      "Epoch 5/50\n",
      "10/10 - 3s - 274ms/step - loss: 0.0490 - val_loss: 0.0213\n",
      "Epoch 6/50\n",
      "10/10 - 3s - 269ms/step - loss: 0.0494 - val_loss: 0.0210\n",
      "Epoch 7/50\n",
      "10/10 - 3s - 271ms/step - loss: 0.0489 - val_loss: 0.0208\n",
      "Epoch 8/50\n",
      "10/10 - 3s - 268ms/step - loss: 0.0499 - val_loss: 0.0208\n",
      "Epoch 9/50\n",
      "10/10 - 3s - 272ms/step - loss: 0.0499 - val_loss: 0.0210\n",
      "Epoch 10/50\n",
      "10/10 - 3s - 270ms/step - loss: 0.0482 - val_loss: 0.0215\n",
      "Epoch 11/50\n",
      "10/10 - 3s - 269ms/step - loss: 0.0495 - val_loss: 0.0207\n",
      "Epoch 12/50\n",
      "10/10 - 3s - 272ms/step - loss: 0.0487 - val_loss: 0.0206\n",
      "Epoch 13/50\n",
      "10/10 - 3s - 275ms/step - loss: 0.0494 - val_loss: 0.0209\n",
      "Epoch 14/50\n",
      "10/10 - 3s - 296ms/step - loss: 0.0516 - val_loss: 0.0207\n",
      "Epoch 15/50\n",
      "10/10 - 3s - 290ms/step - loss: 0.0483 - val_loss: 0.0213\n",
      "Epoch 16/50\n",
      "10/10 - 3s - 298ms/step - loss: 0.0505 - val_loss: 0.0210\n",
      "Epoch 17/50\n",
      "10/10 - 3s - 295ms/step - loss: 0.0491 - val_loss: 0.0214\n",
      "Epoch 18/50\n",
      "10/10 - 3s - 271ms/step - loss: 0.0484 - val_loss: 0.0207\n",
      "Epoch 19/50\n",
      "10/10 - 3s - 273ms/step - loss: 0.0485 - val_loss: 0.0205\n",
      "Epoch 20/50\n",
      "10/10 - 3s - 270ms/step - loss: 0.0485 - val_loss: 0.0205\n",
      "Epoch 21/50\n",
      "10/10 - 3s - 275ms/step - loss: 0.0486 - val_loss: 0.0205\n",
      "Epoch 22/50\n",
      "10/10 - 3s - 271ms/step - loss: 0.0487 - val_loss: 0.0205\n",
      "Epoch 23/50\n",
      "10/10 - 3s - 273ms/step - loss: 0.0489 - val_loss: 0.0205\n",
      "Epoch 24/50\n",
      "10/10 - 3s - 270ms/step - loss: 0.0487 - val_loss: 0.0208\n",
      "Epoch 25/50\n",
      "10/10 - 3s - 272ms/step - loss: 0.0484 - val_loss: 0.0205\n",
      "Epoch 26/50\n",
      "10/10 - 3s - 272ms/step - loss: 0.0498 - val_loss: 0.0208\n",
      "Epoch 27/50\n",
      "10/10 - 3s - 272ms/step - loss: 0.0488 - val_loss: 0.0207\n",
      "Epoch 28/50\n",
      "10/10 - 3s - 271ms/step - loss: 0.0487 - val_loss: 0.0205\n",
      "Epoch 29/50\n",
      "10/10 - 3s - 272ms/step - loss: 0.0484 - val_loss: 0.0204\n",
      "Epoch 30/50\n",
      "10/10 - 3s - 283ms/step - loss: 0.0484 - val_loss: 0.0204\n",
      "Epoch 31/50\n",
      "10/10 - 3s - 270ms/step - loss: 0.0484 - val_loss: 0.0204\n",
      "Epoch 32/50\n",
      "10/10 - 3s - 273ms/step - loss: 0.0485 - val_loss: 0.0204\n",
      "Epoch 33/50\n",
      "10/10 - 3s - 279ms/step - loss: 0.0484 - val_loss: 0.0204\n",
      "Epoch 34/50\n",
      "10/10 - 3s - 268ms/step - loss: 0.0483 - val_loss: 0.0204\n",
      "Epoch 35/50\n",
      "10/10 - 3s - 272ms/step - loss: 0.0484 - val_loss: 0.0204\n",
      "Epoch 36/50\n",
      "10/10 - 3s - 274ms/step - loss: 0.0490 - val_loss: 0.0207\n",
      "Epoch 37/50\n",
      "10/10 - 3s - 265ms/step - loss: 0.0488 - val_loss: 0.0204\n",
      "Epoch 38/50\n",
      "10/10 - 3s - 262ms/step - loss: 0.0487 - val_loss: 0.0207\n",
      "Epoch 39/50\n",
      "10/10 - 3s - 268ms/step - loss: 0.0486 - val_loss: 0.0205\n",
      "Epoch 40/50\n",
      "10/10 - 3s - 274ms/step - loss: 0.0485 - val_loss: 0.0205\n",
      "Epoch 41/50\n",
      "10/10 - 3s - 290ms/step - loss: 0.0484 - val_loss: 0.0204\n",
      "Epoch 42/50\n",
      "10/10 - 3s - 285ms/step - loss: 0.0498 - val_loss: 0.0205\n",
      "Epoch 43/50\n",
      "10/10 - 3s - 288ms/step - loss: 0.0480 - val_loss: 0.0211\n",
      "Epoch 44/50\n",
      "10/10 - 3s - 270ms/step - loss: 0.0487 - val_loss: 0.0204\n",
      "Epoch 45/50\n",
      "10/10 - 3s - 269ms/step - loss: 0.0487 - val_loss: 0.0204\n",
      "Epoch 46/50\n",
      "10/10 - 3s - 269ms/step - loss: 0.0483 - val_loss: 0.0204\n",
      "Epoch 47/50\n",
      "10/10 - 3s - 270ms/step - loss: 0.0484 - val_loss: 0.0204\n",
      "Epoch 48/50\n",
      "10/10 - 3s - 269ms/step - loss: 0.0484 - val_loss: 0.0204\n",
      "Epoch 49/50\n",
      "10/10 - 3s - 271ms/step - loss: 0.0485 - val_loss: 0.0204\n",
      "Epoch 50/50\n",
      "10/10 - 3s - 270ms/step - loss: 0.0483 - val_loss: 0.0204\n",
      "5/5 - 0s - 80ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     21\u001b[39m current_keras_model = model_builder_func(input_len=current_input_len)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# current_keras_model.summary() \u001b[39;00m\n\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Train   modified train_cv function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m cv_run_results = train_cv_modified(\n\u001b[32m     26\u001b[39m     model=current_keras_model,\n\u001b[32m     27\u001b[39m     full_dataset=full_dataset_df, \u001b[38;5;66;03m# Pass the DataFrame\u001b[39;00m\n\u001b[32m     28\u001b[39m     lag_order=current_input_len,\n\u001b[32m     29\u001b[39m     epochs=num_epochs,\n\u001b[32m     30\u001b[39m     batch_size_param=batch_size_for_training,\n\u001b[32m     31\u001b[39m     verbose_param=verbose_level_for_training\n\u001b[32m     32\u001b[39m )\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m#  Store results\u001b[39;00m\n\u001b[32m     35\u001b[39m result_entry = {\n\u001b[32m     36\u001b[39m     \u001b[33m'\u001b[39m\u001b[33minput_len\u001b[39m\u001b[33m'\u001b[39m: current_input_len,\n\u001b[32m     37\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mavg_mse\u001b[39m\u001b[33m'\u001b[39m: cv_run_results[\u001b[33m'\u001b[39m\u001b[33mavg_mse\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# You can add more details from cv_run_results if needed\u001b[39;00m\n\u001b[32m     41\u001b[39m }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mtrain_cv_modified\u001b[39m\u001b[34m(model, full_dataset, lag_order, epochs, patience_es, batch_size_param, verbose_param)\u001b[39m\n\u001b[32m     63\u001b[39m y_pred_scaled_fold = model.predict(X_test_fold_reshaped, verbose=verbose_param)\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Descale predictions and actual values\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m y_pred_descaled_fold = scaler.inverse_transform(y_pred_scaled_fold).flatten()\n\u001b[32m     67\u001b[39m all_fold_predictions.append(y_pred_descaled_fold)\n\u001b[32m     69\u001b[39m y_test_descaled_fold = scaler.inverse_transform(y_test_fold.reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)).flatten()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cemka\\anaconda3\\envs\\dl\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:573\u001b[39m, in \u001b[36mMinMaxScaler.inverse_transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    569\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    571\u001b[39m xp, _ = get_namespace(X)\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m X = check_array(\n\u001b[32m    574\u001b[39m     X,\n\u001b[32m    575\u001b[39m     copy=\u001b[38;5;28mself\u001b[39m.copy,\n\u001b[32m    576\u001b[39m     dtype=_array_api.supported_float_dtypes(xp),\n\u001b[32m    577\u001b[39m     force_writeable=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    578\u001b[39m     ensure_all_finite=\u001b[33m\"\u001b[39m\u001b[33mallow-nan\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    579\u001b[39m )\n\u001b[32m    581\u001b[39m X -= \u001b[38;5;28mself\u001b[39m.min_\n\u001b[32m    582\u001b[39m X /= \u001b[38;5;28mself\u001b[39m.scale_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cemka\\anaconda3\\envs\\dl\\Lib\\site-packages\\sklearn\\utils\\validation.py:1101\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1096\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1097\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdtype=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mnumeric\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1098\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1099\u001b[39m     )\n\u001b[32m   1100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array.ndim >= \u001b[32m3\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1103\u001b[39m         % (array.ndim, estimator_name)\n\u001b[32m   1104\u001b[39m     )\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m   1107\u001b[39m     _assert_all_finite(\n\u001b[32m   1108\u001b[39m         array,\n\u001b[32m   1109\u001b[39m         input_name=input_name,\n\u001b[32m   1110\u001b[39m         estimator_name=estimator_name,\n\u001b[32m   1111\u001b[39m         allow_nan=ensure_all_finite == \u001b[33m\"\u001b[39m\u001b[33mallow-nan\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1112\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "input_lens_to_test = [ 50,60]  # 5 , 10 , 20, 30, 50, 100, 200,\n",
    "model_builders = {\n",
    "    \"BigGRU\": build_big_gru_model,\n",
    "    \"BigGRU2\": build_big_gru_model2,\n",
    "\n",
    "}\n",
    "experiment_results = {name: [] for name in model_builders}\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 50 # \n",
    "# Use global defaults or specify:\n",
    "batch_size_for_training = 16 #  smaller seem sto wrok better fro this amount of data \n",
    "verbose_level_for_training = 2 #  0 for silent, 1 for progress bar\n",
    "\n",
    "\n",
    "for model_name, model_builder_func in model_builders.items():\n",
    "    for current_input_len in input_lens_to_test:\n",
    "        print(f\"--- Training {model_name} with input_len: {current_input_len} ---\")\n",
    "\n",
    "        #  Build the model for the  config\n",
    "        current_keras_model = model_builder_func(input_len=current_input_len)\n",
    "        # current_keras_model.summary() \n",
    "\n",
    "        # Train   modified train_cv function\n",
    "        cv_run_results = train_cv_modified(\n",
    "            model=current_keras_model,\n",
    "            full_dataset=full_dataset_df, # Pass the DataFrame\n",
    "            lag_order=current_input_len,\n",
    "            epochs=num_epochs,\n",
    "            batch_size_param=batch_size_for_training,\n",
    "            verbose_param=verbose_level_for_training\n",
    "        )\n",
    "\n",
    "        #  Store results\n",
    "        result_entry = {\n",
    "            'input_len': current_input_len,\n",
    "            'avg_mse': cv_run_results['avg_mse'],\n",
    "            'std_mse': cv_run_results['std_mse'],\n",
    "            'fold_mses': cv_run_results['fold_mses']\n",
    "            # You can add more details from cv_run_results if needed\n",
    "        }\n",
    "        experiment_results[model_name].append(result_entry)\n",
    "        print(f\"--- Finished {model_name} with input_len: {current_input_len}, Avg MSE: {cv_run_results['avg_mse']:.4f} ---\")\n",
    "        # save model to disk\n",
    "        current_keras_model.save(f\"cem_models/{model_name}_Mse_{cv_run_results['avg_mse']:.2f}_input_len_{current_input_len}.keras\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46386c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Summary ---\n",
      "\n",
      "Model: BigGRU\n",
      "  Input Length: 20, Avg MSE: 226.2021 (+/- 224.9116)\n",
      "  Input Length: 30, Avg MSE: 174.3539 (+/- 151.5426)\n",
      "  Input Length: 40, Avg MSE: 144.0032 (+/- 123.3435)\n",
      "\n",
      "Model: BigLSTM\n",
      "  Input Length: 20, Avg MSE: 495.8087 (+/- 453.9649)\n",
      "  Input Length: 30, Avg MSE: 351.8611 (+/- 335.5473)\n",
      "  Input Length: 40, Avg MSE: 284.8856 (+/- 270.8600)\n",
      "\n",
      "Best Model: BigGRU with Input Length: 40, Avg MSE: 144.0032\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Print final results\n",
    "print(\"\\n--- Experiment Summary ---\")\n",
    "for model_name, results_list in experiment_results.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    if not results_list:\n",
    "        print(\"  No results recorded.\")\n",
    "        continue\n",
    "    for res in results_list:\n",
    "        print(f\"  Input Length: {res['input_len']}, Avg MSE: {res['avg_mse']:.4f} (+/- {res['std_mse']:.4f})\")\n",
    "#print the best model\n",
    "best_model = None\n",
    "best_mse = float('inf')\n",
    "best_model_name = None\n",
    "best_input_len = None\n",
    "for model_name, results_list in experiment_results.items():\n",
    "    for res in results_list:\n",
    "        if res['avg_mse'] < best_mse:\n",
    "            best_mse = res['avg_mse']\n",
    "            best_model_name = model_name\n",
    "            best_input_len = res['input_len']\n",
    "            best_model = res['fold_mses']\n",
    "print(f\"\\nBest Model: {best_model_name} with Input Length: {best_input_len}, Avg MSE: {best_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef5179b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a09668e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3aa23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b01d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2ca93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5a31d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
