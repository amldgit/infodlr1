{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a9257a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 6464.714355  [   60/   73]\n",
      "loss: 3826.565918  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 7125.228516 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 5968.140137  [   60/   73]\n",
      "loss: 3437.791016  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 6621.156738 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 5522.168945  [   60/   73]\n",
      "loss: 3072.309814  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 6162.432617 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 5120.571289  [   60/   73]\n",
      "loss: 2722.211182  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 5752.707520 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 4754.616211  [   60/   73]\n",
      "loss: 2380.294678  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 5366.487793 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 4423.997070  [   60/   73]\n",
      "loss: 2040.386841  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 4999.052734 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 4123.604980  [   60/   73]\n",
      "loss: 1718.909058  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 4660.141113 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3860.980469  [   60/   73]\n",
      "loss: 1422.436646  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 4359.959961 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3645.080078  [   60/   73]\n",
      "loss: 1158.061768  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 4110.003418 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 3482.171875  [   60/   73]\n",
      "loss: 935.807617  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3916.718750 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 3377.759521  [   60/   73]\n",
      "loss: 759.296692  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3782.583008 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 3332.062744  [   60/   73]\n",
      "loss: 632.647400  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3706.060547 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 3339.057617  [   60/   73]\n",
      "loss: 554.336792  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3677.798828 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 3382.161133  [   60/   73]\n",
      "loss: 515.157654  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3680.140137 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 3437.475098  [   60/   73]\n",
      "loss: 501.183624  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3692.443848 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 3481.075439  [   60/   73]\n",
      "loss: 498.306213  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3698.900879 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 3497.204102  [   60/   73]\n",
      "loss: 496.264252  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3693.028320 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 3482.463867  [   60/   73]\n",
      "loss: 491.332550  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3676.627441 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 3443.116943  [   60/   73]\n",
      "loss: 484.832703  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3655.747314 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 3390.317871  [   60/   73]\n",
      "loss: 479.997742  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3636.823486 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 3335.200439  [   60/   73]\n",
      "loss: 479.486328  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3623.884766 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 3285.711182  [   60/   73]\n",
      "loss: 484.036621  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3618.018799 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 3245.868408  [   60/   73]\n",
      "loss: 492.430573  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3617.933838 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 3216.274170  [   60/   73]\n",
      "loss: 502.326172  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3621.166260 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 3195.537598  [   60/   73]\n",
      "loss: 511.116730  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3625.074219 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 3181.502686  [   60/   73]\n",
      "loss: 516.939331  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3627.605225 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 3172.070557  [   60/   73]\n",
      "loss: 518.826721  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3627.694824 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 3165.685059  [   60/   73]\n",
      "loss: 516.576538  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3625.077148 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 3161.446777  [   60/   73]\n",
      "loss: 510.767761  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3620.353760 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 3159.060547  [   60/   73]\n",
      "loss: 502.834961  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3614.206787 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 3158.234619  [   60/   73]\n",
      "loss: 494.222534  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3607.913330 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 3158.856201  [   60/   73]\n",
      "loss: 486.076538  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3602.346191 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 3160.422607  [   60/   73]\n",
      "loss: 479.188934  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3597.916992 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 3162.384766  [   60/   73]\n",
      "loss: 473.936310  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3594.735352 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 3164.020020  [   60/   73]\n",
      "loss: 470.316895  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3592.693115 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 3164.696777  [   60/   73]\n",
      "loss: 468.097504  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3591.589355 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 3164.050049  [   60/   73]\n",
      "loss: 466.967926  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3591.296631 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 3162.091309  [   60/   73]\n",
      "loss: 466.674683  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3591.745117 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 3159.111084  [   60/   73]\n",
      "loss: 467.005463  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3592.850098 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 3155.558594  [   60/   73]\n",
      "loss: 467.768677  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3594.463867 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 3151.895020  [   60/   73]\n",
      "loss: 468.765778  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3596.359863 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 3148.466309  [   60/   73]\n",
      "loss: 469.785309  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3598.260498 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 3145.481689  [   60/   73]\n",
      "loss: 470.615845  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3599.916992 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 3143.052734  [   60/   73]\n",
      "loss: 471.087555  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3601.097412 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 3141.153809  [   60/   73]\n",
      "loss: 471.124268  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3601.697266 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 3139.698975  [   60/   73]\n",
      "loss: 470.731873  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3601.737305 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 3138.618408  [   60/   73]\n",
      "loss: 469.999359  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3601.331787 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 3137.852783  [   60/   73]\n",
      "loss: 469.061493  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3600.645508 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 3137.294922  [   60/   73]\n",
      "loss: 468.057220  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3599.855957 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 3136.844238  [   60/   73]\n",
      "loss: 467.101135  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3599.115967 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 3136.407959  [   60/   73]\n",
      "loss: 466.272339  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3598.542236 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 3135.913086  [   60/   73]\n",
      "loss: 465.610565  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3598.157471 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 3135.296631  [   60/   73]\n",
      "loss: 465.125793  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3598.041504 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 3134.557861  [   60/   73]\n",
      "loss: 464.808838  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3598.189697 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 3133.685547  [   60/   73]\n",
      "loss: 464.627411  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3598.565674 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 3132.709473  [   60/   73]\n",
      "loss: 464.537262  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3599.108154 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 3131.690674  [   60/   73]\n",
      "loss: 464.502411  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3599.778076 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 3130.683838  [   60/   73]\n",
      "loss: 464.483185  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3600.466797 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 3129.727783  [   60/   73]\n",
      "loss: 464.444702  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3601.119141 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 3128.845215  [   60/   73]\n",
      "loss: 464.358276  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3601.662354 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 3128.054932  [   60/   73]\n",
      "loss: 464.207184  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3602.056885 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 3127.362305  [   60/   73]\n",
      "loss: 463.988800  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3602.301270 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 3126.758057  [   60/   73]\n",
      "loss: 463.713654  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3602.424072 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 3126.223877  [   60/   73]\n",
      "loss: 463.402100  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3602.468262 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 3125.738770  [   60/   73]\n",
      "loss: 463.076752  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3602.501465 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 3125.276367  [   60/   73]\n",
      "loss: 462.755920  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3602.558105 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 3124.828369  [   60/   73]\n",
      "loss: 462.453278  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3602.660645 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 3124.368408  [   60/   73]\n",
      "loss: 462.177002  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3602.854980 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 3123.886963  [   60/   73]\n",
      "loss: 461.928986  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3603.130127 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 3123.395508  [   60/   73]\n",
      "loss: 461.719391  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3603.469482 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 3122.897705  [   60/   73]\n",
      "loss: 461.545807  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3603.842041 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 3122.408936  [   60/   73]\n",
      "loss: 461.427795  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3604.232666 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 3121.945068  [   60/   73]\n",
      "loss: 461.298828  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3604.611572 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 3121.507812  [   60/   73]\n",
      "loss: 461.154572  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3604.944824 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 3121.097168  [   60/   73]\n",
      "loss: 460.993073  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3605.225830 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 3120.709961  [   60/   73]\n",
      "loss: 460.814453  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3605.452881 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 3120.348389  [   60/   73]\n",
      "loss: 460.624268  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3605.630615 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 3120.008545  [   60/   73]\n",
      "loss: 460.423157  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3605.772949 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 3119.686035  [   60/   73]\n",
      "loss: 460.214020  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3605.898193 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 3119.380859  [   60/   73]\n",
      "loss: 460.001007  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3606.017334 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 3119.081055  [   60/   73]\n",
      "loss: 459.788910  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3606.159668 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 3118.788818  [   60/   73]\n",
      "loss: 459.581085  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3606.318604 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 3118.495605  [   60/   73]\n",
      "loss: 459.380371  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3606.520508 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 3118.202148  [   60/   73]\n",
      "loss: 459.188110  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3606.772461 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 3117.906494  [   60/   73]\n",
      "loss: 459.003937  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3607.056885 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 3117.604004  [   60/   73]\n",
      "loss: 458.825592  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3607.359375 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 3117.302734  [   60/   73]\n",
      "loss: 458.650421  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3607.695312 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 3117.004883  [   60/   73]\n",
      "loss: 458.476135  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3608.042480 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 3116.711914  [   60/   73]\n",
      "loss: 458.316284  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3608.339600 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 3116.432861  [   60/   73]\n",
      "loss: 458.161987  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3608.548584 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 3116.173828  [   60/   73]\n",
      "loss: 457.985657  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3608.689697 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 3115.931641  [   60/   73]\n",
      "loss: 457.796082  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3608.789062 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 3115.699463  [   60/   73]\n",
      "loss: 457.600037  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3608.860352 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 3115.479004  [   60/   73]\n",
      "loss: 457.418549  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3608.952148 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 3115.256836  [   60/   73]\n",
      "loss: 457.255096  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3609.096680 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 3115.030029  [   60/   73]\n",
      "loss: 457.098877  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3609.278809 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 3114.794922  [   60/   73]\n",
      "loss: 456.948700  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3609.494385 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 3114.557129  [   60/   73]\n",
      "loss: 456.803711  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3609.743652 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 3114.320068  [   60/   73]\n",
      "loss: 456.683380  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3609.988525 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 3114.091309  [   60/   73]\n",
      "loss: 456.552521  [   73/   73]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 3610.190430 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import torch\n",
    "import mert_data as dtu\n",
    "import torch.nn as nn\n",
    "import mert_nn as mnn\n",
    "from mert_nn import train_loop\n",
    "from mert_nn import test_loop\n",
    "\n",
    "n_train = 800\n",
    "n_test = 200\n",
    "shuffle_training_set = False\n",
    "learning_rate = 1e-3\n",
    "sequence_len = 11 # The length of the sequences, it means (sequence_len - 1) past steps and the last one is the label.\n",
    "batch_size = 60\n",
    "mnn.batch_size = batch_size\n",
    "mnn.n_batch_report = 1\n",
    "\n",
    "d_train = dtu.create_training_set(seq_len=sequence_len, n_training_samples=n_train, estimate_missing=False)\n",
    "train_dataloader = torch.utils.data.DataLoader(d_train, batch_size=batch_size, shuffle=shuffle_training_set, num_workers=0)\n",
    "\n",
    "d_test = dtu.create_test_set(seq_len=sequence_len, n_test_samples=n_test, estimate_missing=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(d_test, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "input_size = sequence_len - 1\n",
    "model = mnn.MultiLayerPerceptron(input_size=input_size, hidden_size=64)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
